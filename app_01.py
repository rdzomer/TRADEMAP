import streamlit as st
import requests
from bs4 import BeautifulSoup
import pandas as pd
import time

def scrape_trademap(produto, pais, tipo_dado):
    # URL base (ajuste conforme necess√°rio)
    base_url = "https://www.trademap.org/"
    
    try:
        # Configura√ß√µes de headers para simular navegador
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept-Language': 'en-US,en;q=0.9',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1'
        }
        
        # Sess√£o de requests
        session = requests.Session()
        session.headers.update(headers)
        
        # Primeira requisi√ß√£o para obter cookies/sess√£o
        response = session.get(base_url)
        
        if response.status_code != 200:
            st.error(f"Erro na conex√£o inicial: Status {response.status_code}")
            return None
        
        # Simula√ß√£o de busca (este √© um exemplo fict√≠cio, pode precisar de ajustes)
        search_params = {
            'produto': produto,
            'pais': pais,
            'tipo_dado': tipo_dado
        }
        
        # Exemplo de busca (pode precisar de adapta√ß√µes)
        search_url = f"{base_url}/search?product={search_params['produto']}&country={search_params['pais']}"
        
        # Realizar a busca
        search_response = session.get(search_url)
        
        if search_response.status_code != 200:
            st.error(f"Erro na busca: Status {search_response.status_code}")
            return None
        
        # Parseamento do HTML
        soup = BeautifulSoup(search_response.text, 'html.parser')
        
        # Exemplo de extra√ß√£o de tabela (precisar√° ser ajustado)
        tabela = soup.find('table')
        
        if not tabela:
            st.warning("Nenhuma tabela encontrada")
            return None
        
        # Convers√£o para DataFrame
        df = pd.read_html(str(tabela))[0]
        
        return df
    
    except Exception as e:
        st.error(f"Erro no scraping: {e}")
        return None

# Configura√ß√£o da p√°gina
st.set_page_config(page_title="Consulta TradeMap", layout="centered")
st.title("Consulta ao TradeMap")

# Inputs do usu√°rio
produto = st.text_input("C√≥digo ou nome do produto (ex: 1006)")
pais = st.text_input("Pa√≠s ou regi√£o (ex: Brazil)")
tipo_dado = st.selectbox("Tipo de dado", ["Trade Indicators", "Yearly", "Quarterly", "Monthly"])

# Bot√£o de busca
buscar = st.button("Buscar Dados")

# L√≥gica de busca
if buscar:
    if not produto or not pais:
        st.warning("‚ö†Ô∏è Preencha todos os campos obrigat√≥rios antes de buscar os dados.")
    else:
        with st.spinner("Buscando dados..."):
            # Realizar scraping
            df = scrape_trademap(produto, pais, tipo_dado)
            
            # Apresentar resultados
            if df is not None and not df.empty:
                st.success("‚úÖ Dados coletados com sucesso!")
                st.dataframe(df)
                
                # Bot√£o para download
                st.download_button(
                    "üì• Baixar CSV", 
                    df.to_csv(index=False), 
                    file_name="resultado_trademap.csv", 
                    mime="text/csv"
                )
            else:
                st.warning("‚ö†Ô∏è N√£o foi poss√≠vel encontrar dados para esta consulta.")
